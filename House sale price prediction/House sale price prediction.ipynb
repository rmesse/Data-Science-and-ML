{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# House sale price prediction\n",
    "In this project, we'll work with housing data for the city of Ames, Iowa, United States, from 2006 to 2010. Information on the data set can be found [here](https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627). The prediction models will be based on linear regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data frame has 82 columns and 2930 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "object     43\n",
       "int64      28\n",
       "float64    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "print(\"The data frame has \" + str(len(df.columns)) + \" columns and \" + str(len(df)) + \" rows.\"  )\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by creating a function, `train_and_test()`, which takes three inputs:\n",
    "- a data frame\n",
    "- the columns to be selected for the model, including the target column\n",
    "- the target column ('SalePrice' by default)\n",
    "\n",
    "The function will:\n",
    "- select the columns for the model\n",
    "- split the data frame into a training set and a test set\n",
    "- instantiate and train a linear regression model using only numeric columns as variables\n",
    "- predict the target variable on the test set\n",
    "- return the rooted mean squared error (`rmse`) between predicted and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57120.50729008638"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_test(df,\n",
    "                   features,\n",
    "                   target = 'SalePrice'):  \n",
    "        \n",
    "    # Feature selection\n",
    "    df = df[features]\n",
    "    \n",
    "    # Train and test data split\n",
    "    train = df[:int(len(df)/2)]\n",
    "    test = df[int(len(df)/2):]\n",
    "             \n",
    "    # Selection of numeric columns\n",
    "    train = train.select_dtypes(include=['integer', 'float'])\n",
    "    test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    # Model\n",
    "    features = train.columns.drop(target)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "rmse = train_and_test(df,[\"Gr Liv Area\", \"SalePrice\"])\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will transform (function `transform_features()`) each numeric column with missing values by filling in with the most common value in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    vals = df.mode(numeric_only=True)\n",
    "    vals = vals.iloc[0].to_dict()\n",
    "    df = df.fillna(vals)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create new features, based on existing features, that better represent information relevant for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2927"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    vals = df.mode(numeric_only=True)\n",
    "    vals = vals.iloc[0].to_dict()\n",
    "    df = df.fillna(vals)\n",
    "    \n",
    "    # New features\n",
    "    df['Years Before Sale'] = df['Yr Sold'] - df['Year Built']\n",
    "    df['Years Since Remod'] = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    \n",
    "    # Removal of rows with negative values for both of these new features\n",
    "    indexes_to_remove = (df['Years Before Sale']<0) | (df['Years Since Remod']<0)\n",
    "    indexes_to_remove = df[indexes_to_remove].index\n",
    "    df = df.drop(indexes_to_remove)\n",
    "            \n",
    "    return  df\n",
    "len(transform_features(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop columns (function `remove_features()`) that:\n",
    "- aren't useful as predictors ('PID' and 'Order')\n",
    "- leak data about the final sale ('Mo Sold', 'Sale Condition', 'Sale Type', 'Yr Sold', information about each column can be found [here](https://s3.amazonaws.com/dq-content/307/data_description.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_features(df,\n",
    "                    features_to_remove=[\"PID\", \"Order\",\"Mo Sold\", \n",
    "                                        \"Sale Condition\", \"Sale Type\", \n",
    "                                        \"Yr Sold\",\"Year Built\", \n",
    "                                        \"Year Remod/Add\" ]):\n",
    "    df = df.drop(features_to_remove,axis=1)\n",
    "    return  df\n",
    "len(remove_features(df).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will update the `remove_features()` function so as to drop:\n",
    "- any column with 5% or more missing values\n",
    "- any text columns with 1 or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_features(df,features_to_remove=[\"PID\", \"Order\",\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\" ]):\n",
    "    df = df.drop(features_to_remove,axis=1)\n",
    "    \n",
    "    # Remove columns with more than 5% missing values\n",
    "    remove = df.isnull().sum() > 5/100*len(df)\n",
    "    remove = remove.index[remove]\n",
    "    df = df.drop(remove, axis=1)\n",
    "    \n",
    "    # Remove text columns with missing values\n",
    "    remove = df.select_dtypes(include='object').isnull().sum()>0\n",
    "    remove = remove.index[remove]\n",
    "    df = df.drop(remove, axis=1)\n",
    "    \n",
    "    return  df\n",
    "\n",
    "len(remove_features(df).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select numeric columns most useful for the prediction, we will compute correlation coefficients between 'SalePrice' and the other columns. Numeric columns with low correlation coefficient (a threshold of 0.4 is the default) with the target variable are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_features(df,\n",
    "                    features_to_remove=[\"PID\", \"Order\",\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\" ],\n",
    "                    target = 'SalePrice',\n",
    "                    coeff_threshold=0.4):\n",
    "    df = df.drop(features_to_remove,axis=1)\n",
    "    \n",
    "    # Remove columns with more than 5% missing values\n",
    "    remove = df.isnull().sum() > 5/100*len(df)\n",
    "    remove = remove.index[remove]\n",
    "    df = df.drop(remove, axis=1)\n",
    "    \n",
    "    # Remove text columns with missing values\n",
    "    remove = df.select_dtypes(include='object').isnull().sum()>0\n",
    "    remove = remove.index[remove]\n",
    "    df = df.drop(remove, axis=1)\n",
    "    \n",
    "    # Remove numeric columns with low correlation coefficient with the target variable\n",
    "    correlations = df.select_dtypes(exclude='object').corr()[target].abs().sort_values()\n",
    "    df=df.drop(correlations[correlations < coeff_threshold].index,axis=1)\n",
    "    \n",
    "    return  df\n",
    "\n",
    "len(remove_features(df).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which columns in the data frame should be converted to the categorical data type? All of the columns that can be identified as nominal variables are candidates for being converted to categorical. Based on the [documentation of the data set](https://s3.amazonaws.com/dq-content/307/data_description.txt), the following are nominal features: `PID`, `MS SubClass`, `MS Zoning`, `Street`, `Alley`, `Land Contour`, `Lot Config`, `Neighborhood`, `Condition 1`, `Condition 2`, `Bldg Type`, `House Style`, `Roof Style`, `Roof Matl`, `Exterior 1st`, `Exterior 2nd`, `Mas Vnr Type`, `Foundation`, `Heating`, `Central Air`, `Garage Type`, `Misc Feature`, `Sale Type`, and `Sale Condition`. We will create a function (`convert_to_category()`) that:\n",
    "- converts these features to the categorical type\n",
    "- if a categorical column has more than 10 (aribtrary cutoff) unique values, we might drop it, since  we don't want more than 10 columns to be added to the data frame when we dummy code this column\n",
    "- creates dummy columns and adds them back to the dataframe, while dropping the original text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_category(df,\n",
    "                        nominal_features=[\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                        \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                        \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                        \"Misc Feature\", \"Sale Type\", \"Sale Condition\"],\n",
    "                        uniq_threshold=10):\n",
    "    \n",
    "    # Select only nominal features present in the data frame\n",
    "    nominal_features_to_keep = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            nominal_features_to_keep.append(col)\n",
    "    \n",
    "    # Check if the input nominal features correspond to text columns\n",
    "    df_text_cols = df[nominal_features_to_keep].dtypes == 'object'\n",
    "    if df_text_cols.all() == False:\n",
    "        print(\"Error in `nominal_features` argument: not all of the specified columns are text columns!\")\n",
    "        return df_text_cols\n",
    "    \n",
    "    # Remove text columns in the data frame not among the input nominal features\n",
    "    text_cols_to_remove = []\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col not in nominal_features_to_keep:\n",
    "            text_cols_to_remove.append(col)\n",
    "    df = df.drop(text_cols_to_remove, axis=1)\n",
    "    \n",
    "    # Drop nominal features with more than `uniq_threshold` categories\n",
    "    uniqueness_counts = df[nominal_features_to_keep].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > uniq_threshold].index.tolist()\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    # Conversion to categorical type\n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Create dummy columns and add them back to the dataframe, while dropping the original text columns\n",
    "    new_cols = pd.get_dummies(df.select_dtypes(include=['category']))\n",
    "    df = pd.concat([df,new_cols], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_subset = remove_features(df)\n",
    "len(convert_to_category(df_subset).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will now update the `train_and_test()` function in order to incorporate row randomization and cross-validation. Also, we will remove the `features` argument, since these will be selected by the other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29410.06249325091, 38224.87576403876, 28434.03806000115, 29418.745660257788]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31371.930494387154"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_test(df,\n",
    "                   target = 'SalePrice',\n",
    "                   k=0):  \n",
    "    \n",
    "    # If k == 1, randomize all rows (frac=1) from `df` once\n",
    "    if k == 1:\n",
    "        df = df.sample(frac=1)\n",
    "    \n",
    "    # Train and test data split\n",
    "    train = df[:int(len(df)/2)]\n",
    "    test = df[int(len(df)/2):]\n",
    "             \n",
    "    # Selection of numeric columns\n",
    "    train = train.select_dtypes(include=['integer', 'float'])\n",
    "    test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    # Model\n",
    "    features = train.columns.drop(target)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[target])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[target], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # If k > 1, iterate over k-folds\n",
    "    if k > 1:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(train[features], train[target])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[target], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        print(rmse_values)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "df_subset = transform_features(df)\n",
    "df_subset = remove_features(df_subset)\n",
    "df_subset = convert_to_category(df_subset)\n",
    "rmse = train_and_test(df_subset,k=4)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
